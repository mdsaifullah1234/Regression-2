{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Explain the concept of R-squared in linear regression models. How is it calculated, and what does it \n",
    "represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS  = R-squared (coefficient of determination) measures the proportion of variance in the dependent variable that is explained by the independent variables in a linear regression model. It is calculated as the ratio of the explained variance to the total variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. Define adjusted R-squared and explain how it differs from the regular R-squared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS = Adjusted R-squared is a modified version of R-squared that adjusts for the number of predictors in the model. It penalizes the addition of unnecessary predictors and provides a more accurate measure of model fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. When is it more appropriate to use adjusted R-squared ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS = Adjusted R-squared is more appropriate when comparing models with different numbers of predictors or when assessing the goodness of fit in multiple regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. What are RMSE, MSE, and MAE in the context of regression analysis? How are these metrics \n",
    "calculated, and what do they represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS = RMSE (Root Mean Squared Error), MSE (Mean Squared Error), and MAE (Mean Absolute Error) are metrics used to evaluate the performance of regression models. RMSE is the square root of the average of squared differences between predicted and actual values. MSE is the average of squared differences, and MAE is the average of absolute differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Discuss the advantages and disadvantages of using RMSE, MSE, and MAE as evaluation metrics in \n",
    "regression analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS = Advantages: RMSE and MSE penalize larger errors more than MAE, making them sensitive to large errors. MAE is less sensitive to outliers. Disadvantages: RMSE and MSE can be heavily influenced by outliers, while MAE treats all errors equally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. Explain the concept of Lasso regularization. How does it differ from Ridge regularization, and when is \n",
    "it more appropriate to use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS = Lasso regularization adds a penalty term to the loss function that is proportional to the absolute value of the coefficients. It encourages sparse solutions by shrinking some coefficients to zero. Ridge regularization, on the other hand, adds a penalty term proportional to the square of the coefficients. Lasso is more appropriate when feature selection is desired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. How do regularized linear models help to prevent overfitting in machine learning? Provide an \n",
    "example to illustrate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS = Regularized linear models prevent overfitting by adding a penalty term to the loss function, which discourages large coefficients and complex models. For example, in Lasso regularization, some coefficients are shrunk to zero, effectively performing feature selection and reducing model complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8. Discuss the limitations of regularized linear models and explain why they may not always be the best \n",
    "choice for regression analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS  = Limitations of regularized linear models include the need to choose an appropriate regularization parameter, which may require tuning. They may also be sensitive to the scale of the features and multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9. You are comparing the performance of two regression models using different evaluation metrics. \n",
    "Model A has an RMSE of 10, while Model B has an MAE of 8. Which model would you choose as the better \n",
    "performer, and why? Are there any limitations to your choice of metric ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS  = It depends on the specific context and requirements of the problem. RMSE penalizes larger errors more than MAE, so Model A with a lower RMSE may be preferred if minimizing large errors is critical. However, MAE provides a more robust measure of central tendency and is less affected by outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10. You are comparing the performance of two regularized linear models using different types of \n",
    "regularization. Model A uses Ridge regularization with a regularization parameter of 0.1, while Model B \n",
    "uses Lasso regularization with a regularization parameter of 0.5. Which model would you choose as the \n",
    "better performer, and why? Are there any trade-offs or limitations to your choice of regularization \n",
    "method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS  = The choice depends on the specific characteristics of the problem and the importance of feature selection. If feature selection is desired, Lasso regularization (Model B) may be preferred due to its ability to shrink coefficients to zero. However, Ridge regularization (Model A) may be more appropriate if preserving all features is important or if there are highly correlated predictors."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
